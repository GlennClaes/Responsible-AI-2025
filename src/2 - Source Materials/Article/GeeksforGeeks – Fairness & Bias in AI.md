## Source Material 

2025-10-28 13:23

Status: Draft 
Tags: [[Source Material]] [[3 - Tags/Article|Article]] [[Fairness]] [[Bias]]

# Fairness and Bias in Artificial Intelligence

**Author(s):** sneha03 (Username)
**Publication:** GeeksforGeeks
**Date Published:** August 6, 2025 (Last Updated)
**URL:** https://www.geeksforgeeks.org/artificial-intelligence/fairness-and-bias-in-artificial-intelligence/

## Summary

This article provides a detailed overview of fairness and bias in artificial intelligence (AI). It defines bias in AI as errors leading to unfair decisions, stemming from various sources including data, algorithms, and human biases. Fairness is defined as the attempt to correct algorithmic bias and ensure equitable treatment, promoting trust and equality. The article discusses various types of bias and fairness, and outlines strategies for addressing these issues throughout the AI development lifecycle.

## Key Points

- **Bias Definition:** Bias in AI is an error leading to unfair decisions, often stemming from societal inequalities or flawed data/algorithms. Identifying and addressing bias is crucial for trust and equality.

- **Types of Bias** 
	- **Sampling Bias:** Occurs when the training dataset taken is not diverse and doesn't include the whole population it serves. 
	- **Algorithmic Bias:** Occurs due to faults in the design and implementation of the algorithm. 
	- **Confirmation Bias:** Occurs when the system uses the pre-existing biases held by the users or system programmers and arrives at conclusions based on them. 
	- **Measurement Bias:** Occurs when the data collected measures certain groups and over or under-represents them. 
	- **Generative Bias:** Occurs in generative AI models when the model output has unbalanced representations in the content. 
	- **Reporting Bias:** Occurs when the frequency of the events in the training dataset and real-world frequency don't match. 
	- **Automation Bias:** Occurs when automated systems are favored more than non-automated systems, even when error rates are considered.
	- **Group Attribution Bias:** Tends to generalize that individuals also have the same beliefs as the group they belong to.

- **Fairness Definition:** Fairness in AI aims to correct algorithmic bias (e.g., based on race, ethnicity) in automated decision-making, connecting fairness with equality and justice. It's subjective but essential to prevent discrimination.

- **Types of Fairness** 
	- **Group Fairness:** Ensures that distinct groups are treated equally in the AI system. 
	- **Individual Fairness:** Ensures that similar individuals are treated equally and similarly by the AI systems. 
	- **Procedural Fairness:** Ensures that the decision-making process is fair and transparent. 
	- **Counterfactual Fairness:** Ensures that AI systems are fair in all situations, even during hypothetical scenarios. 
	- **Causal Fairness:** Ensures that the system doesn't make decisions based on historical biases and inequalities by focusing on causal relationships.

- **Addressing Fairness and Bias:** Requires a multi-faceted approach across the AI lifecycle: Data Collection (representative data), Algorithmic Design (bias mitigation), Training (fairness constraints), Evaluation (fairness metrics), Transparency (explainability), Monitoring (auditing), and Policy/Governance (regulations).

## Quotes

> "The bias in AI can be defined as the error that leads to unfair decisions."

> "Fairness in artificial intelligence can be defined as an attempt to correct the algorithmic bias such as race or ethnicity etc in an automated decision-making process."

> "Fairness is an intentional goal that works to mitigate bias and bias on the other hand is an unintentional error that occurs in the system."

## References

(No external references were listed)