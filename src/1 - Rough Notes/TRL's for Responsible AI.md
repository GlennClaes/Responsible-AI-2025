### What is a TRL?

TRL = Technology Readiness Level
TRL's are a scale (from 1 to 9) used to measure how mature a technology is, from idea to real-world use.

- TRL 1: Basic principles observed and reported
- TRL 2: Technology concept and/or application formulated
- TRL 3: Analytical and experimental critical function and/or characteristic proof of concept
- TRL 4: Technology validated in a laboratory environment
- TRL 5: Technology validated in relevant environment
- TRL 6: Technology demonstrated in relevant environment
- TRL 7: System prototype demonstration in operational environment
- TRL 8: System complete and qualified
- TRL 9: Actual system proven in operational environment (commercial application)

### TRL's for Responsible AI

Responsible AI is currently considered to be around TRL 4-6. It's principles and tools have moved beyond theory and are being developed, tested and demonstrated in practice, but are not yet fully implemented at scale. Responsible AI tools such as fairness checks that look for bias in an AI system have mostly been tested in research settings or controlled environments. As development progresses, tools are starting to be applied in real projects and company trials to understand how effectively they work in practice. Responsible AI has not yet reached full maturity, as it is still not widely or consistently used across industries and clear standards and regulations are still being established. 

- Complex and multi-dimensional nature: Responsible AI involves ethics, governance, fairness and human oversight. Although many tools and frameworks exist, their use is still uneven across sectors.
- Limited generality: Most Responsible AI methods are built for specific fields, such as finance or healthcare, rather than being widely applicable across different domains.
- Institutional and regulatory gaps: Many organizations and countries lack clear governance systems, regulations and trained staff to fully apply Responsible AI in practice.
- Constantly changing technology: Because AI evolves rapidly, Responsible AI must continuously adapt to new risks and systems. This ongoing change prevents it from reaching full and stable maturity.

### Different parts of Responsible AI and their TRL's

- Fairness and Bias Detection Tools (TRL 6-7): These tools help identify and reduce unfair treatment or bias in AI systems. They are already being used in real projects, such as hiring or credit scoring. However, they are not yet common in every organization or industry, which is why they have not reached the highest TRL.
- Explainability and Transparency Methods (TRL 5-6): These methods aim to make AI decisions easier to understand for humans. They are used in some areas, like healthcare and finance, but still struggle with complex models such as deep neural networks. Because of these challenges, their maturity is in the middle range.
- Human Oversight and Accountability Systems (TRL 5-6): This part ensures that humans stay in control and are responsible for AI decisions. Some industries already use these systems, but their adoption is still limited. More work is needed to make them consistent and reliable across different fields.
- Societal and Regulatory Adoption (TRL 3-4): Laws, public awareness and international standards for Responsible AI are still in the early stages. While initiatives such as the EU AI Act show progress, many countries and sectors are still developing their approaches.

### Summary

Technology Readiness Levels are used to measure how mature a technology is, from early research to full use. Responsible AI currently sits around TRL 4â€“6, meaning it has moved beyond theory and lab testing but is not yet fully implemented or standardized across industries.

Responsible AI includes several parts that are developing at different speeds. Fairness and bias detection tools are among the most advanced, as they are already used in real projects. Explainability and transparency methods and human oversight systems are moderately mature, with practical use in some sectors but still facing challenges. Societal and regulatory adoption remains at an early stage, as clear laws, standards and consistent global adoption are still being developed.

Overall, Responsible AI is progressing, but not yet at full maturity due to its complex ethical and technical nature, limited generalization across domains, uneven institutional readiness and the fast-changing pace of AI technology.

### Sources

1. McKinsey & Company, Insights on Responsible AI from the Global AI Trust Maturity Survey, 2023. Online. Available: https://www.mckinsey.com/capabilities/tech-and-ai/our-insights/tech-forward/insights-on-responsible-ai-from-the-global-ai-trust-maturity-survey
2. GSMA, The GSMA Responsible AI Maturity Roadmap, 2024. Online. Available: https://www.gsma.com/solutions-and-impact/connectivity-for-good/external-affairs/wp-content/uploads/2024/09/GSMA-ai4i_The-GSMA-Responsible-AI-Maturity-Roadmap_v8.pdf
3. S. Stoyanovich et al., Towards a Responsible AI Organizational Maturity Model, Microsoft Research, 2022. Online. Available: https://www.microsoft.com/en-us/research/publication/towards-a-responsible-ai-organizational-maturity-model/
4. PwC, Responsible AI: Maturing from Theory to Practice, 2023. [Online]. Available: https://www.pwc.com/gx/en/issues/data-and-analytics/artificial-intelligence/what-is-responsible-ai/pwc-responsible-ai-maturing-from-theory-to-practice.pdf
5. L. Guite, Responsible AI Readiness Index: A Tool to Track the Progress and Impact of Responsible AI, International Monetary Fund (IMF), Nov. 2024. Online. Available: https://www.imf.org/en/News/Seminars/Conferences/2024/11/20/12th-statistical-forum
